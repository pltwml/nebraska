{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Lecture 6\n",
    "=======\n",
    "\n",
    "Outline\n",
    "---------\n",
    "\n",
    "### I Introduction to the convolution operation\n",
    "\n",
    "### II Building blocks of ConvNets\n",
    "> A. Convolutional kernels\n",
    ">\n",
    "> B. Pooling\n",
    ">\n",
    "> C. Strides and downsampling\n",
    ">\n",
    "> D. Equivariance and Invariance of the Convolutional Filters\n",
    ">\n",
    "> E. Schematic picture of the CNN architecture at work\n",
    "\n",
    "### III First applications of CNN\n",
    "> A. The first use case: MNIST\n",
    ">\n",
    "> B. Real CNN test: Dogs vs. Cats dataset\n",
    ">\n",
    "> C. Dataset augmentation\n",
    ">\n",
    "> D. VGG16 and features extraction learning\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "I Introduction to the convolution operation\n",
    "----------------\n",
    "\n",
    "### Convolution in physics dates back at least to Huygensa and superpositon principle\n",
    "> A. Given a signal x(t) and filter w(t-a) we define their convolution as\n",
    "\n",
    "![Image](gfx/convDefinition.png \"Convolution definition\")\n",
    "> Simple interpretation:\n",
    ">> We average (or smear-out) the input signal x(t) with the weight w(t-s) at locations (t-s)\n",
    ">>\n",
    ">> For example this can be time-decaying average of a temporal series up to the present time t\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### For NN image processing one has a discrete 2D convolution:\n",
    "\n",
    "![Image](gfx/conv2D.png \"Convolution in 2D\")\n",
    "\n",
    "> A. In principle this linear operation can be generalized to arbitrary tensors\n",
    ">\n",
    "> B. For finite ranges of the indices care must be taken for the boundary elements (more on this later on: padding)\n",
    ">\n",
    "> C. The above case tranforms one 2D map into another 2D map, and is realized by a single convolution 'kernel' K\n",
    ">\n",
    "> D. In general one can consider collections of kernels, or kernel tensors\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "II Building blocks of Convolutional Networks\n",
    "----------------\n",
    "\n",
    "### Consider 2D image data processing\n",
    "> A. Suppose we have images represented as 3D tensors V_{i,l,m} within 4D batches, with i labeling channels, e.g. RGB and l, m labelling space\n",
    ">\n",
    "> We wish to apply to it a convolution represented by a 4D tensor K_{i,j,m,n}, which would yield another 3D tensor: the layer output\n",
    ">\n",
    "> The aim is to transform multi-channel representation of the data into another multi-channel representation, preserving channeled 2D image structure\n",
    "> \n",
    "> B. For the case at hand we have the output tensor Z_{i,j,k}:\n",
    "\n",
    "![Image](gfx/convNetFormula.png \"2D CNN Convolution\")\n",
    ">\n",
    "> Here i and j labels input and output layers channels, while m, n labels width and height offsets between the corresponding pixels \n",
    ">\n",
    "> C. This algebraic structure replaces Dense layers of old and defines new input-output maps of the CNN network\n",
    ">\n",
    "> D. The output size is decreased by two pixels per direction (H x W). One has to treat boundary with zero-padding to preserve the size.\n",
    ">\n",
    "> E. Numerous constraints imposed on the structure of K_{i,j,m,n} define fifferent types of convolutional networks\n",
    ">\n",
    "> F. The foremost demand in CNNs is that K is a block matrix dominated by small number of identical sub-kernels families {K_1, K_2, ...}_{i,j,m,n}<<K_{i,j,m,n}, and sparse (zero) otherwise\n",
    ">\n",
    "> G. In most cases a further demand is introduced, that for the given layer i all the sub-kernels are identical: K_1=K_2=...\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### How is it different from the Dense layer?\n",
    "> A. The most crucial difference is the sparse connectivity with parameter sharing along the layer\n",
    ">\n",
    "> B. We demand, that for the given layer index kernel contains only few different parameters, replicated many times with only limited local connections to the input data tensor\n",
    "> \n",
    "> In practise that means, that kernel consists of small local sets of connections, as opposed to Dense layer, and that each set of connections has the same set of weights. \n",
    ">\n",
    "> C. These sets are called receptive fields and constitute learnable filters, core objects of the CNN architecture\n",
    ">\n",
    "> D. Further, we output many channels corresponding to the label i, not just one as in the Dense case\n",
    ">\n",
    "> E. Each output channel is the result of the local filter action and represents presence of the corresponfing feature in the data sample\n",
    ">\n",
    "> F. Such an architecture has dramatically reduced spatial (storage complexity) and far reduced inference time cost\n",
    ">\n",
    "> G. For example: processing a picture of 320 x 280 pixels for vertical edge detection:\n",
    ">> Direct matrix multiplication implementation: 320 x 280 x 319 x 280 ~ 8x10^9 parameters\n",
    ">>\n",
    ">> Convolutional implementation: 2 x 319 x 280 ~ 180 x 10*3 parameters\n",
    ">\n",
    "> I. The network can still represent non-local correlations by employing deep leayers ('shadow casting')\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Parameter sharing consequences\n",
    "> A. An important property emerges in ConvNets: local feature maps (results of convolutions) become approximately translationally equivariant\n",
    ">\n",
    "> B. This means, that the given layer is in fact a characteristic function of a given feature and will detect it anywhere in the input data tensor\n",
    ">\n",
    "> C. Other possible symmetries are less obvious to implement\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pooling, strides and downsampling\n",
    "> A. Convolutional layers work in ConvNets together with Pooling layers\n",
    ">\n",
    "> B. The role of Pooling is to select the most prominent features, as observed by Conv layer, and substantially reduce the output layer size by the striding operation parametrized by an integer s\n",
    ">\n",
    "> C. Stride is basically a shift between neighboaring filter application: s>1 skips some pixels\n",
    "> \n",
    "> D. There are numerous schemes for Pooling feature selection: \n",
    ">> Max Pooling\n",
    ">>\n",
    ">> Average Pooling\n",
    ">>\n",
    ">> Clustering\n",
    ">>\n",
    ">> Weighted geometric averaging\n",
    ">>\n",
    ">> Learnable Pooling\n",
    ">\n",
    "> E. In any case the result is a new output layer of size N/s, with N the input layer size\n",
    ">\n",
    "> F. This operation effectively downsamples feature maps, futher reducing spatio-temporal complexity of the model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pooling and downsampling consequences\n",
    "\n",
    "> A. A cricual property emerging from MaxPooling is translational invariance of the feature detection\n",
    ">\n",
    "> B. CNN looses precise information on the given feature locus in favor of its presence detection: 'if it is, not where it is'\n",
    "> \n",
    "> C. This in fact is an assumption about the dataset, and can be wrong!\n",
    ">\n",
    "> D. Convolutions and Pooling may lead to undefitting, if their invariances are absent from the dataset.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Schematic picture of CNN at work\n",
    "-----------\n",
    "\n",
    "\n",
    "### A. The idea: hierarchical image decomposition preserving local spatial correlations:\n",
    "\n",
    "![Image](gfx/cnn-cat-assembly.jpg \"CNN Cat Assembly\")\n",
    "\n",
    "### B. In practise, introduce local receptive fields: patches observing small portions of the feature map\n",
    "\n",
    "![Image](gfx/cnn-action.jpg \"CNN Action\")\n",
    "\n",
    "### C. Basic ConvNet stack for images\n",
    "\n",
    "> ### 1. Start from 3D (not 1D) input image tensor (Height, Width, Channels): (28, 28, 1) or (H, W, 3) for RGB\n",
    ">\n",
    "> ### 2. Introduce new elements: many small \"convolutional kernels\" defining local trainable feature filters, typically shaped (3, 3) or (5, 5). There can be great many of them in the given layer.\n",
    ">\n",
    "> ### 3. Scan each pixel of the image with kernels and produce corresponding new output map pixel channels\n",
    ">\n",
    "> ### 4. Downsample image by MaxPooling: select the most prominent local features\n",
    "> \n",
    "> ### 5. Repeat layer stack as many times as needed\n",
    ">\n",
    "> ### 6. Introduce Dense layers and output to construct classifier mapping to cathegories\n",
    "\n",
    "### D. Convolution action in detail\n",
    "\n",
    "![Image](gfx/cnn-conv-layer-decomposition.png \"CNN Conv Layer Decomposition\")\n",
    "\n",
    "### E. Local patches: valid convolution points with (3, 3) kernel\n",
    "\n",
    "![Image](gfx/cnn-conv-padding.png \"CNN Valid Convolution\")\n",
    "\n",
    "### F. Zero-Padding for boundary effects mitigation with (3, 3) kernel\n",
    "\n",
    "![Image](gfx/cnn-conv-padding2.png \"CNN Padding\")\n",
    "\n",
    "### G. Receptive field action: same size, filtered output\n",
    "\n",
    "![Image](gfx/cnn-receptive-field.jpg \"CNN receptive field\")\n",
    "\n",
    "### H. Strides: \n",
    "> ### Downsampling, used with pooling and sometimes with kernels\n",
    ">\n",
    "> ### This step is crucial for reducing network parameters count and allowing for wide scope of the deep receptive fields: 'hyperbolic' vs linear structure of the network (like AdS space!)\n",
    ">\n",
    "> ### Translation invariance and global correlations appear due to the locally maximal feature selection\n",
    "\n",
    "![Image](gfx/cnn-conv-stride.png \"CNN Stride - Downsampling\")\n",
    "\n",
    "### I. Cat image activations in a deeper (4th) layer\n",
    "![Image](gfx/cnn-4th-layer-activations.png \"4th layer activations\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III Applications\n",
    "-------\n",
    "\n",
    "### MNIST\n",
    "### Cats vs Dogs\n",
    "### Transfer learning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
